## 2021-10-17  

## AIæ‹Ÿå£°: 5ç§’å†…å…‹éš†æ‚¨çš„å£°éŸ³å¹¶ç”Ÿæˆä»»æ„è¯­éŸ³å†…å®¹  
https://github.com/babysor/MockingBird  
https://github.com/babysor/Realtime-Voice-Clone-Chinese  

## Cloud-native neural search framework for ğ™–ğ™£ğ™® kind of data  
https://github.com/jina-ai/jina  

## Matlab-dtw  
https://github.com/HYH1104/Matlab-dtw  

## PaddlePaddle-DeepSpeech  
https://github.com/yeyupiaoling/PaddlePaddle-DeepSpeech/issues  

## esp-dl  
https://github.com/espressif/esp-dl  

## maix-asr  
çœ‹sipeedçš„è®ºå›ï¼Œä¼¼ä¹å®˜æ–¹æ˜¯åšäº†ä¸€ä¸ªè¯­éŸ³è¯†åˆ«çš„æ¨¡å‹ä¾‹å­ï¼Œç§°ä¸ºmaix-asrï¼š  
https://github.com/sipeed/MaixPy_scripts/blob/master/multimedia/speech_recognizer/test_maix_asr.py  
è‡³äºèƒ½å¦ä½¿ç”¨ä¸çŸ¥é“ï¼ˆå› ä¸ºä¸Šæ¬¡maixé‚£ä¸ªå¾ˆç®€å•çš„asréƒ½æ²¡è·‘é€šï¼‰ã€‚  
è¿™é‡Œæœ‰ç¯‡ä»‹ç»ï¼šblog.csdn.net/xuguoliang757/article/details/118462079  

## æ·±åº¦è¯­éŸ³è¯†åˆ«ï¼ˆä¸€ï¼‰â€”â€”æ¦‚è¿°, CTC  
https://antkillerfarm.github.io/speech/2019/02/26/Deep_ASR.html  
æ·±åº¦è¯­éŸ³è¯†åˆ«ï¼ˆä¸‰ï¼‰â€”â€”è¯­éŸ³è¯†åˆ«å‚è€ƒèµ„æº  
https://antkillerfarm.github.io/speech/2019/03/13/Deep_ASR_3.html  

## è¶…è½»é‡çº§ä¸­æ–‡ocrï¼Œæ”¯æŒç«–æ’æ–‡å­—è¯†åˆ«, æ”¯æŒncnnã€mnnã€tnnæ¨ç†  
https://github.com/DayBreak-u/chineseocr_lite  

## Numpy.NET  
https://github.com/SciSharp/Numpy.NET  

## Hands-on Speech Recognition with Kaldi/TIMIT  
https://zhuanlan.zhihu.com/p/62083288  
https://www.amazon.com/Hands-Speech-Recognition-Kaldi-TIMIT/dp/B08P1CFHQY  
??? not found  

## Qlib is an AI-oriented quantitative investment platform  
https://github.com/microsoft/qlib  

## A Python library for adding effects to audio.  
https://github.com/spotify/pedalboard  

## An End-to-End Architecture for Keyword Spotting and Voice Activity Detection  
https://github.com/mindorii/kws  

## MLOps-Basics  
https://github.com/graviraja/MLOps-Basics  

## SciSharp  
https://github.com/SciSharp/NumSharp  
https://github.com/SciSharp/Numpy.NET  

## lite.ai  
https://github.com/DefTruth/lite.ai/blob/main/ort/cv/yolox.cpp  

## wenet  
https://github.com/wenet-e2e/wenet  
https://github.com/wenet-e2e/wenet-kws  
https://gitee.com/ytzy/wenet/  
æ‰“ç ´å›½å¤–å„æ–­ï¼Œå‡ºé—¨é—®é—®ä¸»å¯¼ç ”å‘çš„ç«¯åˆ°ç«¯è¯­éŸ³è¯†åˆ«å¼€æºæ¡†æ¶ WeNet å®è·µä¹‹è·¯  
ä»Šå¹´(2021å¹´) 2 æœˆï¼Œä¸­å›½äººå·¥æ™ºèƒ½å…¬å¸å‡ºé—¨é—®é—®è”åˆè¥¿åŒ—å·¥ä¸šå¤§å­¦æ¨å‡ºäº†å…¨çƒé¦–ä¸ªé¢å‘äº§å“å’Œå·¥ä¸šç•Œçš„ç«¯åˆ°ç«¯è¯­éŸ³è¯†åˆ«å¼€æºå·¥å…· â€”â€” WeNetã€‚  
https://www.infoq.cn/article/oqlNys5qlQWRkYuEZkEG  
äº¬ä¸œï¼šåŸºäºWeNetçš„ç«¯åˆ°ç«¯è¯­éŸ³è¯†åˆ«ä¼˜åŒ–æ–¹æ¡ˆä¸è½åœ°  
https://baijiahao.baidu.com/s?id=1710860423889509910&wfr=spider&for=pc  
```
resample å¼€æºåœ°å€: https://github.com/fanlu/wenet/commit/bfded32a4f8c35fe1383bba5a45d29f0ffde40a0  
ONNX æ”¯æŒå¼€æºåœ°å€ï¼šhttps://github.com/fanlu/wenet/commit/40062b065405280b5ae679c8e6d91a2333294d0a  
WeNet multi_cn æ”¯æŒï¼šhttps://github.com/wenet-e2e/wenet/pull/210  
kaldi: https://github.com/kaldi-asr/kaldi  
k2: https://github.com/k2-fsa/snowfall/pull/59  
ESPnet: https://github.com/espnet/espnet  
EESEN: https://github.com/srvk/eesen  
```  
WeNet: Production oriented Streaming and Non-streaming End-to-End Speech Recognition Toolkit  
https://arxiv.org/abs/2102.01547  
ã€WeNetï¼šé¢å‘å·¥ä¸šè½åœ°åº”ç”¨çš„è¯­éŸ³è¯†åˆ«å·¥å…·åŒ…ï¼Œæä¾›äº†ä»è¯­éŸ³è¯†åˆ«æ¨¡å‹çš„è®­ç»ƒåˆ°éƒ¨ç½²çš„ä¸€æ¡é¾™æœåŠ¡ã€‘â€™WeNet - Production First and Production Ready End-to-End Speech Recognition Toolkit' by WeNet Open Source Community GitHub: github.com/wenet-e2e/wenet paper:ã€ŠWeNet: Production First and Production Ready End-to-End Speech Recognition Toolkitã€‹  

## Maix-Speech  
https://github.com/sipeed/Maix-Speech  

## BBC micro:bit and more  
https://etchk.screenstepslive.com/s/etcsup  
https://etchk.screenstepslive.com/s/etcsup/m/86471/l/1064859-i-o-board-micro-bit-program  
äººå·¥æ™ºèƒ½  
https://etchk.screenstepslive.com/s/codingnstem  
https://etchk.screenstepslive.com/s/codingnstem/m/104070  

## micro:bit mbed  
http://swf.com.tw/?p=1270  
https://github.com/lancaster-university/codal-microbit  
https://github.com/lancaster-university/microbit-v2-samples  
https://github.com/kant/microbit-v2-samples  

## Flashlight, asr    
* https://github.com/flashlight/flashlight/tree/main/flashlight/app/asr  
* ã€flashlightï¼šå¿«é€Ÿã€çµæ´»çš„C++æœºå™¨å­¦ä¹ åº“ï¼Œç”±Facebook AIç ”ç©¶è¯­éŸ³å›¢é˜ŸåŠTorchå’ŒDeep Speechçš„åˆ›ä½œè€…ç”¨C++ç¼–å†™ã€‘  
* â€™flashlight - a fast, flexible machine learning library written entirely in C++ from the Facebook AI Research Speech team and the creators of Torch and Deep Speech'  

## NeuralSpeech  
ã€NeuralSpeechï¼šå¾®è½¯äºšç ”é™¢çš„ç ”ç©¶é¡¹ç›®ï¼Œä¸“æ³¨äºåŸºäºç¥ç»ç½‘ç»œçš„è¯­éŸ³å¤„ç†ï¼ŒåŒ…æ‹¬è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)ã€æ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢(TTS)ç­‰ã€‘  
'NeuralSpeech - a research project in Microsoft Research Asia focusing on   
neural network based speech processing, including automatic speech   
recognition (ASR), text to speech (TTS), etcâ€™ by Microsoft  
* https://github.com/microsoft/NeuralSpeech  

## ã€ŠC++æ¨¡æ¿å…ƒç¼–ç¨‹å®æˆ˜ï¼šä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¡†æ¶çš„åˆæ­¥å®ç°ã€‹  
https://github.com/bluealert/MetaNN-book  
https://github.com/liwei-cpp/MetaNN  

## fastai  
https://docs.fast.ai  

## Python+TensorFlowæœºå™¨å­¦ä¹ å®æˆ˜, ç¬¬9ç«     
search baidupan, TensorFlowæœºå™¨å­¦ä¹ å®æˆ˜  
https://github.com/pannous/tensorflow-speech-recognition  
https://github.com/llSourcell/tensorflow_speech_recognition_demo  
https://github.com/mingdebaba/code/tree/master/å®ä¾‹æºä»£ç /09  
https://github.com/illool/TensorFlow/blob/master/ChineseTrain/train.py  
https://github.com/dreaaim/testrepo/tree/master/LearningAlgorithm/VoiceClassify  

## FPGA  
* https://github.com/lambdaconcept/mfcc  
* https://github.com/AlexKly/Simple-Voice-Activity-Detector-using-MFCC-based-on-FPGA-Kintex  

## åŠ¨æ‰‹å­¦PyTorchæ·±åº¦å­¦ä¹ å»ºæ¨¡ä¸åº”ç”¨  
* search baidupan, åŠ¨æ‰‹å­¦PyTorch  
* ç¬¬8ç«  PyTorchéŸ³é¢‘å»ºæ¨¡  

## CH32V307-EVT-R1, CH32V307VCT6, VoiceRcgExamï¼šç‹¬ç«‹è¯è¯­éŸ³è¯†åˆ«ä¾‹ç¨‹   
* CH32V307EVT.ZIP  
https://www.wch.cn/search?t=all&q=ch32v307  
https://www.wch.cn/downloads/CH32V307EVT_ZIP.html  
es8388.h  
VoiceRcg.h  
libVoiceRcg.a  
calc_chara_para_match_dis  
https://github.com/openwch/ch32v307/blob/main/EVT/EXAM/VoiceRcgExam/VoiceRcgExam/User/VoiceRcg.h  
* CH32V307-EVT-R1å¼€å‘æ¿ï¼ˆèŠ¯ç‰‡CH32V307VCT6ï¼‰æä¾›äº†ä¸€ä¸ªç‹¬ç«‹è¯è¯†åˆ«ä¾‹ç¨‹ï¼Œæˆ‘çœ‹è¿‡æ˜¯é—­æºçš„ï¼Œ  
åº”è¯¥ç±»ä¼¼äºk210(maixduino)æœ€å¼€å§‹çš„è¯­éŸ³è¯†åˆ«ä¾‹å­é‚£æ ·ï¼Œé€šè¿‡è®­ç»ƒè¯´è¯äººï¼ˆè¯´è¯äººç‰¹å®šï¼‰çš„å¤šæ¬¡å½•å…¥  
ï¼ˆå…³é”®è¯æ•° * æ¯ä¸ªè¯çš„è®­ç»ƒæ•°ï¼‰ï¼Œæœ€åè¯†åˆ«å‡ºæ˜¯å“ªä¸ªå…³é”®è¯ï¼ˆä¾‹å­ä¸­æ˜¯å››ä¸ªå…³é”®è¯ä¸Šä¸‹å·¦å³ï¼‰â€”â€”  
å½“ç„¶è¿™æ˜¯ä¸ªé—­æºé™æ€åº“ï¼Œè‡³äºæ˜¯å¦æ˜¯ç›¸åŒç®—æ³•ç®—å‡ºMFCCå°±ä¸æ¸…æ¥šäº†ï¼Œå¤§æ¦‚æ˜¯k210ï¼ˆmaixduinoï¼‰  
ç›¸ä¼¼æˆ–è€…ç›¸åŒçš„ç®—æ³•MFCC-DTWã€‚å¯èƒ½è‡ªå¸¦äº†VADåœ¨é—­æºé™æ€åº“é‡Œå¤´ã€‚è¾“å…¥æ˜¯ç”¨ES8388ï¼ˆé€šè¿‡I2Sï¼‰æˆ–ADC  

## Arduino Audio Tools  
* https://github.com/pschatzmann/arduino-audio-tools  
* https://github.com/pschatzmann/rp2040-i2s  

## Accord.net audio process    
* https://github.com/accord-net  
* http://accord-framework.net  
* http://accord-framework.net/docs/html/N_Accord_Audio_Filters.htm  

## MSGEQ7  

## EasyCV  
* https://github.com/alibaba/EasyCV  

## HanLP  
* https://github.com/zluckymn/HanlpNet  

## sherpa-ncnn  
* https://github.com/k2-fsa/sherpa-ncnn  

## LFCC  
* https://github.com/yunnong770/Speaker-Verification/blob/main/LFCC_LPCC_MFCC_CQCC/Supporting_Func/LFCC/extract_lfcc.m  

## LPCC  
* https://github.com/fwkz/lpcc-speech-recognition  

## VoiceRecognition  
* https://github.com/SpEcHiDe/CS4089/tree/gh-pages/WORK_DONE/VoiceRecognition  

## LibXtract, lpcc  
* https://github.com/jamiebullock/LibXtract/blob/master/src/vector.c  
* https://github.com/GanAlps/Extracting-Features-from-audio  

## scikits.talkbox.features MFCC (like Pythonæœºå™¨ç»å…¸å®ä¾‹, python_speech_features MFCC)  
* https://github.com/cournape/talkbox/blob/master/scikits/talkbox/features/mfcc.py    
* search scikits.talkbox.features, MFCC for usage  

## (TODO) åŸºäºDNNå’ŒDTWç®—æ³•é…åˆVADæˆªå–çš„å¾®è¯­éŸ³è¯†åˆ«æ¡†æ¶, some sources lost  
* https://github.com/search?l=C&p=1&q=dtw&type=Repositories  
* https://github.com/jerenhu/MiniSpeech  

## tflite micro  
* https://www.tensorflow.org/lite/microcontrollers  
* https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/examples/micro_speech  
* https://github.com/raspberrypi/pico-tflmicro/tree/main/examples/micro_speech  
* https://github.com/espressif/tflite-micro-esp-examples/tree/master/examples/micro_speech/main  
* https://learn.sparkfun.com/tutorials/using-sparkfun-edge-board-with-ambiq-apollo3-sdk/example-applications  
* https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#0  
* https://github.com/sparkfun/SparkFun_Edge  

## search torch nn functional librosa sklearn spect  
* https://github.com/search?l=Jupyter+Notebook&p=3&q=torch+nn+functional+librosa+sklearn+spect&type=Code  
* Speech-classification  
* è¿™ç¯‡æ–‡ç« æ—¨åœ¨å¸®åŠ©éŸ³é¢‘åˆ†ç±»åˆå­¦è€…æ›´å¥½åœ°äº†è§£éŸ³é¢‘åˆ†ç±»çš„ç›¸å…³å†…å®¹  
* https://github.com/UnReAlKiNg/Speech-classification  
* speechcommand  
* https://github.com/work2544/speechcommand  

## xr872 vad  
webrtc_vad_demoç”¨äºæ¼”ç¤ºvadè¯­éŸ³è¾“å…¥æ£€æµ‹åŠŸèƒ½  
xr872_xradio_skylark_sdk_1.0.2_vad_demo.7z  
https://xradiotech-developer-guide.readthedocs.io/zh/latest/zh_CN/application-guide/  

## æ ‘è“æ´¾ä½¿ç”¨snowboyä»¥åŠç™¾åº¦è¯­éŸ³apiå®ç°è¯­éŸ³è¯†åˆ«åŠ©æ‰‹  
https://www.passerma.com/article/54/  
https://github.com/passerma/voiceAssistant  

## åœ¨ esp32c3 ç”¨ ncnn è·‘ç¥ç»ç½‘ç»œ mnist  
* https://github.com/nihui/ncnn_on_esp32  
* https://zhuanlan.zhihu.com/p/492142807  

## PaddleHub è¯­éŸ³åˆ†ç±», è¯­éŸ³è¯†åˆ«    
* https://github.com/PaddlePaddle/PaddleHub/tree/develop/demo/audio_classification  
* https://github.com/PaddlePaddle/PaddleHub  
* https://aistudio.baidu.com/aistudio/projectdetail/4397882?channelType=0&channel=0  

## https://github.com/zycv/awesome-keyword-spotting  

## https://github.com/sipeed/libmaix  

## https://github.com/Ai-Thinker-Open/aithinker_Ai-M6X_SDK/blob/master/examples/tinymaix/main.c  
tinymaix  


## å£°å­¦å›å£°æ¶ˆé™¤(AEC)  
* X1000\packages\example\Sample\aec  
* ingenic-linux-kernel3.10.14-x1000-v9.0-20191212.tar.bz2  

## VITS è¯­éŸ³åˆæˆ  
* https://github.com/xiaoyou-bilibili/tts_vits  

## OpenAI Whisper ASR, Robust Speech Recognition via Large-Scale Weak Supervision      
* https://github.com/openai/whisper  
* æˆ‘å°è¯•ç”¨openai-whisperåšè¯­éŸ³è¯†åˆ«ï¼Œå¯èƒ½æ˜¯ç¦»çº¿çš„ï¼ˆè£…æ—§ç‰ˆæœ¬ï¼Œæ”¯æŒpython-3.7ï¼Œæ–°ç‰ˆæœ¬ä¸æ”¯æŒï¼‰ï¼Œç”¨aistudioå®‰è£…ï¼Œæˆ‘æµ‹è¯•è¿‡è‹±è¯­è¯†åˆ«å¾ˆå‡†ï¼Œdeepspeechçš„ä¸‰ä¸ªæµ‹è¯•éŸ³é¢‘éƒ½è¯†åˆ«å‡ºæ¥ï¼Œå°æ¨¡å‹æ–‡ä»¶æ¯”è¾ƒå°ï¼ˆåªæœ‰500Må·¦å³ï¼‰ï¼Œæ¯”deepspeechå°ï¼Œä½†è¯†åˆ«é€Ÿåº¦è¾ƒæ…¢ï¼Œcpuç‰ˆä¸‹ï¼Œè‹±æ–‡å•è¯éœ€è¦30ç§’å·¦å³ï¼Œå¥å­éœ€è¦45ç§’å·¦å³  
* pip install openai-whisper==20230117  
æœ€æ–°ç‰ˆä¸æ”¯æŒpython3.7ï¼ˆ3.8ï¼Ÿï¼‰ï¼Œæ‰€ä»¥è¦è£…æ—§ç‰ˆ  
* çœ‹githubé¡¹ç›®çš„è¯´æ˜ï¼š  
https://github.com/openai/whisper  
* /home/aistudio/.cache/whisper/small.pt exists, 461M  
* $ whisper yes.2a6d6pep.wav --language en
UserWarning: FP16 is not supported on CPU; using FP32 instead  
warnings.warn("FP16 is not supported on CPU; using FP32 instead")  
Yes.  
* å•è¯éœ€è¦30ç§’  
need 46sec  
* $ tar xzf audio-0.6.0.tar.gz  
$ cd audio  
$ whisper 2830-3980-0043.wav --language en  
Experience proves this.  
$ whisper 4507-16021-0012.wav --language en  
 Why should one halt on the way?  
$ whisper 8455-210777-0068.wav --language en  
 Your power is sufficient, I said.  
* tiny model  
$ whisper yes.2a6d6pep.wav --language en --model tiny.en  
72.1M  
* ä¸Šæ¬¡è¯´çš„é‚£ä¸ªopenai-whisperçš„è¯­éŸ³è¯†åˆ«ï¼Œå®é™…ä¸Šè¿˜æœ‰æ›´å°çš„æ¨¡å‹æ–‡ä»¶ï¼Œ  
tiny-enåªæœ‰70å¤šMï¼Œæ•ˆæœå·®ä¸å¤šï¼Œ  
é€Ÿåº¦æ›´å¿«ï¼ˆè¯†åˆ«å•è¯å¤§æ¦‚éœ€è¦8ç§’ï¼‰ã€‚  
å½“ç„¶å®ƒé»˜è®¤çš„smallæ¨¡å‹åº”è¯¥æ˜¯è€ƒè™‘å¤šè¯­è¨€çš„æ··åˆè¯†åˆ«ï¼Œæ‰€ä»¥ä¼šè¯†åˆ«å¾—å¾ˆæ…¢  
* https://github.com/ggerganov/whisper.cpp  

## äººå·¥æ™ºèƒ½å¼€å‘ç³»åˆ—(6) è¯­éŸ³å‘½ä»¤è¯†åˆ«  
* https://t.rock-chips.com/forum.php?mod=viewthread&tid=456&extra=page%3D1  
* https://t.rock-chips.com/wiki.php?filename=è½¯ä»¶å¼€å‘/AIå¼€å‘#hash_4  
* search baiduapn, è¯­éŸ³å‘½ä»¤è¯†åˆ«.txt  

## ç™¾åº¦è¯­éŸ³, æ‹¼éŸ³ç›¸ä¼¼åº¦  
* similarwordsV1.zip  
* https://platform.bj.bcebos.com/sdk/asr/asr_doc/doc_download_files/similarwordsV1.zip  
* https://ai.baidu.com/ai-doc/SPEECH/Ik38lxqbt  

## ç™¾åº¦è¯­éŸ³, éŸ³é¢‘è½¬ç   
* https://ai.baidu.com/ai-doc/SPEECH/7k38lxpwf  
* ç¤ºä¾‹æ–‡ä»¶, public.zip  
* https://platform.bj.bcebos.com/sdk/asr/asr_doc/doc_download_files/public.zip  
* wav æ–‡ä»¶è½¬ 16k 16bits ä½æ·±çš„å•å£°é“pcmæ–‡ä»¶  
```
ffmpeg -y  -i 16k.wav  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 16k.pcm
```
* 44100 é‡‡æ ·ç‡ å•å£°é“ 16bts pcm æ–‡ä»¶è½¬ 16000é‡‡æ ·ç‡ 16bits ä½æ·±çš„å•å£°é“pcmæ–‡ä»¶  
```
ffmpeg -y -f s16le -ac 1 -ar 44100 -i test44.pcm  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 16k.pcm  
```
* mp3 æ–‡ä»¶è½¬ 16K 16bits ä½æ·±çš„å•å£°é“ pcmæ–‡ä»¶
```
ffmpeg -y  -i aidemo.mp3  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 16k.pcm
```
* etc
```
// -acodec pcm_s16le pcm_s16le 16bits ç¼–ç å™¨
// -f s16le ä¿å­˜ä¸º16bits pcmæ ¼å¼
// -ac 1 å•å£°é“
//  -ar 16000  16000é‡‡æ ·ç‡
ffmpeg -y  -i aidemo.mp3  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 16k.pcm
é€šç”¨å‚æ•°ï¼š -y
è¾“å…¥éŸ³é¢‘mp3æ–‡ä»¶å‚æ•°ï¼š -i aidemo.mp3
è¾“å‡ºéŸ³é¢‘ 16000é‡‡æ ·ç‡ å•å£°é“ pcm æ ¼å¼ï¼š  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 16k.pcm
ç¤ºä¾‹ï¼š è¾“å…¥æ˜¯ 32000HZçš„å•å£°é“ 16bits pcmæ–‡ä»¶ã€‚æŸ¥è¯¢ä¸‹æ–‡çš„è¾“å…¥å‚æ•°ä¸º â€œ -f s16le -ac 1 -ar 32000 -i test32.pcmâ€ è¾“å‡ºæ˜¯ 16000HZçš„å•å£°é“ 16bits pcmæ–‡ä»¶ã€‚æŸ¥è¯¢ä¸‹æ–‡çš„è¾“å‡ºå‚æ•°ä¸º â€œ-f s16le -ac 1 -ar 16000 16k.pcmâ€ å¸¸ç”¨å‚æ•°é€‰æ‹© -y
åˆå¹¶å¦‚ä¸‹ï¼š
ffmpeg  -y  -f s16le -ac 1 -ar 32000  -i test32.pcm -f s16le -ac 1 -ar 16000 16k.pcm
-i  test.wav # æˆ–test.mp3 æˆ–è€… test.amr
è¾“å…¥ pcmæ ¼å¼ï¼š pcméœ€è¦é¢å¤–å‘ŠçŸ¥ç¼–ç æ ¼å¼ï¼Œé‡‡æ ·ç‡ï¼Œå•å£°é“ä¿¡æ¯
-acodec pcm_s16le -f s16le -ac 1 -ar 16000 -i 8k.pcm
// å•å£°é“ 16000 é‡‡æ ·ç‡  16bitsç¼–ç  pcmæ–‡ä»¶
// s16le  s(signied)16(16bits)le(Little-Endian)
-acodec pcm_s16leï¼šä½¿ç”¨s16leè¿›è¡Œç¼–ç 
-f s16le æ–‡ä»¶æ ¼å¼æ˜¯s16leçš„pcm
-ac 1 ï¼šå•å£°é“
-ar 16000 ï¼š 16000é‡‡æ ·ç‡
è¾“å‡ºéŸ³é¢‘å‚æ•°
åœ¨åŸå§‹é‡‡æ ·ç‡ å¤§äºæˆ–è€…æ¥è¿‘16000çš„æ—¶å€™ï¼Œæ¨èä½¿ç”¨16000çš„é‡‡æ ·ç‡ã€‚ 8000çš„é‡‡æ ·ç‡ä¼šé™ä½è¯†åˆ«æ•ˆæœã€‚ è¾“å‡ºwavå’Œamræ ¼å¼æ—¶ï¼Œå¦‚æœä¸æŒ‡å®šè¾“å‡ºç¼–ç å™¨ï¼Œffmpegä¼šé€‰å–é»˜è®¤ç¼–ç å™¨ã€‚
è¾“å‡ºpcméŸ³é¢‘ï¼š
-f s16le -ac 1 -ar 16000 16k.pcm
// å•å£°é“ 16000 é‡‡æ ·ç‡ 16bitsç¼–ç  pcmæ–‡ä»¶
è¾“å‡ºwav éŸ³é¢‘ï¼š
-ac 1 -ar 16000 16k.wav
// å•å£°é“ 16000 é‡‡æ ·ç‡ 16bitsç¼–ç  pcmç¼–ç çš„wavæ–‡ä»¶
è¾“å‡ºamr-nb éŸ³é¢‘ ï¼š
å…¨ç§°æ˜¯ï¼šAdaptive Multi-Rateï¼Œè‡ªé€‚åº”å¤šé€Ÿç‡ï¼Œæ˜¯ä¸€ç§éŸ³é¢‘ç¼–ç æ–‡ä»¶æ ¼å¼ï¼Œä¸“ç”¨äºæœ‰æ•ˆåœ°å‹ç¼©è¯­éŸ³é¢‘ç‡ã€‚åœ¨å¸¦å®½ä¸æ˜¯ç“¶é¢ˆçš„æƒ…å†µä¸‹ï¼Œä¸å»ºè®®é€‰æ‹©è¿™ç§æ ¼å¼ï¼Œè§£å‹éœ€è¦ç™¾åº¦æœåŠ¡å™¨é¢å¤–çš„è€—æ—¶ amr-nbæ ¼å¼åªèƒ½é€‰ 8000é‡‡æ ·ç‡ã€‚bit ratesè¶Šé«˜éŸ³è´¨è¶Šå¥½ï¼Œä½†æ˜¯æ–‡ä»¶è¶Šå¤§ã€‚ bit rates 4.75k, 5.15k, 5.9k, 6.7k, 7.4k, 7.95k, 10.2k or 12.2k
8000çš„é‡‡æ ·ç‡åŠæœ‰æŸå‹ç¼©ä¼šé™ä½è¯†åˆ«æ•ˆæœã€‚å¦‚æœåŸå§‹é‡‡æ ·ç‡å¤§äº16000ï¼Œè¯·ä½¿ç”¨ amr-wbæ ¼å¼ã€‚
-ac 1 -ar 8000 -ab 12.2k 8k-122.amr
// 8000 é‡‡æ ·ç‡ 12.2 bitRates
è¾“å‡º amr-wb æ ¼å¼ï¼Œé‡‡æ ·ç‡ 16000ã€‚ bit ratesè¶Šé«˜éŸ³è´¨è¶Šå¥½ï¼Œä½†æ˜¯æ–‡ä»¶è¶Šå¤§ã€‚ 6600 8850 12650 14250 15850 18250 19850 23050 23850
-acodec amr_wb -ac 1 -ar 16000 -ab 23850 16k-23850.amr
è¾“å‡ºm4aæ–‡ä»¶
æŸ¥çœ‹è¯­éŸ³åˆæˆç”Ÿæˆçš„MP3æ ¼å¼ä¿¡æ¯ï¼š
ffprobe -v quiet -print_format json -show_streams  aidemo.mp3
ç¼–è¯‘è¿‡libfdk_aac ffmpeg ç¤ºä¾‹
ffmpeg -y -f s16le -ac 1 -ar 16000 -i 16k_57test.pcm -c libfdk_aac  -profile:a aac_low -b:a 48000 -ar 16000 -ac 1 16k.m4a
MP4Box -brand mp42:0 16k.m4a #è¿™æ­¥ä¸èƒ½å¿½ç•¥
é™æ€ç‰ˆæœ¬è‡ªå¸¦çš„aacåº“ç¤ºä¾‹
ffmpeg -y -f s16le -ac 1 -ar 16000 -i 16k_57test.pcm -c aac  -profile:a aac_low -b:a 48000 -ar 16000 -ac 1 16k.m4a 
MP4Box -brand mp42:0 16k.m4a #è¿™æ­¥ä¸èƒ½å¿½ç•¥
è¾“å‡ºå‚æ•°
-c é€‰ç¼–ç åº“ libfdk_aacæˆ–è€…aac
-profile:a profileå›ºå®šé€‰aac_lowï¼ˆAAC-LCï¼‰ï¼Œrestapiä¸æ”¯æŒ ä¾‹å¦‚HE-AAC ï¼ŒLDï¼ŒELDç­‰
-b:a bitrates ï¼Œ 16000é‡‡æ ·ç‡å¯¹åº”çš„bitrates CBR èŒƒå›´ä¸º 24000-96000ã€‚è¶Šå¤§çš„è¯ï¼Œå¤±çœŸè¶Šå°ï¼Œä½†æ˜¯æ–‡ä»¶è¶Šå¤§
-ar é‡‡æ ·ç‡ï¼Œä¸€èˆ¬å›ºå®š16000
-ac å›ºå®š1ï¼Œå•å£°é“
æŸ¥çœ‹ m4a æ ¼å¼
ffprobe 16k.m4a
```
* whisper.cppçš„è½¬æ¢  
see https://github.com/ggerganov/whisper.cpp  
```
ffmpeg -i input.mp3 -ar 16000 -ac 1 -c:a pcm_s16le output.wav
```

