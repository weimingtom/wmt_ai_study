https://blog.csdn.net/weixin_34191734/article/details/91964709

这几天基于清华大学的中文语音训练集 做一个识别语音转文本的模型，发现训练过程非常的慢，难以忍受。8911个音频文件，大概2g多的数据，使用GPU训练4轮居然要2个小时。如果训练16轮的话，就是8个小时。如果训练80轮的话，就是40个小时。

为了缩短训练时间，我重新检查了程序。

首先，发现batch_size只有16，太小了。我的GPU有6G显存，完全可以改大点。于是把batch_size改成32. 

其次，我使用python -m cProfile 跟踪程序，发现librosa.load(wav, mono=True)方法很费时间。这个librosa音频数据处理工具负责加载音频文件，加载一个音频文件居然要0.2秒，奇葩。百度了librosa，果然有人说它的性能很差。经过对比，把librosa.load(wav, mono=True)方法换成scipy.io.wavfile.read(wav)，能够大幅加速音频文件的读取和加载速度。（librosa的性能讨论帖  https://github.com/librosa/librosa/issues/572）

#这段代码性能很差 wav, sr = librosa.load(wav_files[pointer], mono=True)
sr, wav = scipy.io.wavfile.read(wav_files[pointer])
wav = wav.astype('float32') / 32767
mfcc = np.transpose(librosa.feature.mfcc(wav, sr), [1, 0])
修改完这两块地方，重新开始训练，果然速度大幅提升。训练16轮，2小时14分跑完。对比原来的8小时，改进了不少。：）

 

后记： 这次测试用的是Tensorflow0.12，总体感觉有些慢。此外，感觉用python处理大数据确实有点性能问题。以后凡是用纯python实现的处理大数据的方法都得留意一下。只要怀疑有问题，可以用profile工具跟踪看看。

-----------------------------------------------------------------------------------------------------

2017-5-15更新

再次做了一次优化：

1）批量正则化系数从 1e-8 改成 (1e-5 + 1e-12), 变大了。

2）把激活函数从“tanh” 改成 “relu”。因为理论上relu收敛地更快，表现更好。

然后，开始16轮的训练。这次，2小时8分跑完。对比优化前的2小时14分，又快了一点。而且，观察每轮打印出来的loss矩阵，明显收敛速度非常快。训练结束后，大部分的loss都在200以下，比优化前好很多。

此外，用一段语音对训练生成的模型做测试，得到了更多的文字信息（仍然不准确），而不是优化前的两个文字。

-----------------------------------------------------------------------------------------------------

2017-5-16更新

把从8911个文件里抽取的音频特征向量和标签向量保存成一个numpy大文件（500多M）。训练前，加载numpy文件到内存中。这样每轮训练都直接从内存中的numpy对象里获取，加载时间大幅减少。经过这样优化后，再次训练16轮只需要1小时36分左右的时间。


转载于:https://my.oschina.net/qinhui99/blog/899014
